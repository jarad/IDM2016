\documentclass[handout]{beamer}

\usetheme{AnnArbor}
\usecolortheme{beaver}

\setlength{\unitlength}{\textwidth}  % measure in textwidths
\usepackage[normalem]{ulem}

\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{enumerate items}[default]
\setbeamertemplate{enumerate subitem}{\alph{enumii}.}
\setbeamertemplate{enumerate subsubitem}{\roman{enumiii}.}
\setkeys{Gin}{width=0.6\textwidth}

\title[Forecasting from low counts]{Stochastic dynamic models for low count observations}
\subtitle{(and forecasting from them)}
\author[Jarad Niemi]{Dr. Jarad Niemi}
\institute[ISU]{Iowa State University}
\date{\today}

\begin{document}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=6, fig.height=5, 
               size='tiny', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE,
               cache=TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE>>=
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(tlpl)
@

<<set_seed>>=
set.seed(1)
@

\frame{\maketitle}

% \begin{frame}
% \frametitle{Outline}
% 
% \begin{itemize}
% \item 
% \end{itemize}
% \end{frame}

\begin{frame}{Overview}
\tableofcontents
\end{frame}

\section{Poisson-binomial state-space model}
\begin{frame}
\frametitle{Poisson-binomial state-space model}
Let $X_{tk}$ be the count of the number of individuals in state $k$ and time $t$. We model state transitions using Poisson distributions, i.e. \[ 
\begin{array}{rll}
	\Delta X_{tk} &\stackrel{ind}{\sim} Po(\lambda_{k} f_k(X_{t-1})), \\
	X_{tm} &= X_{t-1,m} + \sum_{k=1}^K v_{mk} \Delta X_{tk}, & m=1,\ldots,M 
\end{array}
\]
where $f_k(\cdot)$ are known functions and $v_{mk}$ is a known \emph{stoichiometry}. 

\vspace{0.2in} \pause

We assume the transitions $\Delta X_{tk}$ are partially observed through a binomial distribution, \pause i.e. 
\[ 
Y_{tk} \stackrel{ind}{\sim} Bin(\Delta X_{tk},\theta_{k}).
\]

\end{frame}

\subsection{Simulations}
\begin{frame}
\frametitle{SIR modeling simulations}

<<state_sim>>=
sir = sckm('sir')
n = 52
d = tau_leap(sir, n)
d$X = as.data.frame(d$X)
names(d$X) = sir$states
d$X$time = 0:n
X = gather(d$X, state, count, -time)
@

<<state_sims_plot, dependson="state_sim">>=
ggplot(X, aes(time,count,color=state,linetype=state)) + 
  geom_line(size=2)
@
\end{frame}




\begin{frame}
\frametitle{SIR modeling simulations}

<<state_sims>>=
sir = sckm('sir')
n = 52

d = rdply(1000, {
  d = tau_leap(sir, n)
  d$X = as.data.frame(d$X)
  names(d$X) = sir$states
  d$X$time = 0:n
  gather(d$X, state, count, -time)
})

q = d %>% 
  group_by(time,state) %>%
  summarise(L = quantile(count,.025),
            U = quantile(count,.975))

ggplot(q, aes(time,ymin=L,ymax=U,fill=state)) +
  geom_ribbon(alpha=0.5)
@
\end{frame}


\begin{frame}
\frametitle{Variability as a function of population size}

<<state_sim_population>>=
sir = sckm('sir')
n = 52


d = ddply(data.frame(N=10^(2:4)), .(N), function(x) {
  sir = sckm('sir')
  sir$X[1] = x$N*.99
  sir$X[2] = x$N*.01
  sir$mult[1] = 1/x$N
  
  rdply(1e3, {
    d = tau_leap(sir, n)
    d$X = as.data.frame(d$X)
    names(d$X) = sir$states
    d$X$time = 0:n
    gather(d$X, state, count, -time)
  })
})

q = d %>% 
  group_by(time,state,N) %>%
  summarise(L = quantile(count,.025),
            U = quantile(count,.975)) %>%
  mutate(Lp = L/N,
         Up = U/N)
@

<<dependson='state_sim_population'>>=
ggplot(q, aes(time,ymin=L,ymax=U,fill=state)) +
  geom_ribbon(alpha=0.5) +
  facet_wrap(~N)
@

\end{frame}


\begin{frame}
\frametitle{Forecasts for proportion of population}
<<dependson='state_sim_population'>>=
ggplot(q, aes(time,ymin=Lp,ymax=Up,fill=state)) +
  geom_ribbon(alpha=0.5) +
  facet_wrap(~N)
@
\end{frame}







\section{Inference and forecasting}
\begin{frame}
\frametitle{Forecasting with perfect information}

Suppose you know transition rates $\lambda$, observation probabilities $\theta$, and the states $X_{0:t}$ and your only goal is to forecast the future states $X_{t+1:T}$, \pause i.e. 

\[ p(X_{t+1:T}|\theta,\lambda,X_{0:t})=p(X_{t+1:T}|\theta,\lambda,X_{t}) \]
\pause 
this distribution is estimated via Monte Carlo simulation.
\end{frame}


\begin{frame}
<<perfect_forecasts>>=
# Initial simulation
sir = sckm('sir')
n = 51
d = tau_leap(sir, n)
d$X = as.data.frame(d$X)
names(d$X) = sir$states
d$X$time = 0:n
d$X = d$X %>%
  filter((time %% 10) == 0) %>%
  mutate(start_time = time)
#X = gather(d$X, state, count, -time)

# For each time-point forward simulate to the end
# and then calculate quantiles
dd = ddply(d$X, .(start_time), function(x) {
  rdply(1e3, {
    sir = sckm('sir')
    n = 52-x$time
    sir$X = x[,c("S","I","R")]
    d = tau_leap(sir, n)
    d$X = as.data.frame(d$X)
    names(d$X) = sir$states
    d$X$time = x$start_time:52
    d$X %>%
      gather(state, count, -time)
  })
})

q = dd %>% 
  group_by(start_time,time,state) %>%
  summarise(L = quantile(count,.025),
            U = quantile(count,.975)) 
@

<<dependson='perfect_forecasts'>>=
q$start_time = paste("t=", q$start_time)
ggplot(q, aes(time, ymin=L, ymax=U, fill=state)) +
  geom_ribbon(alpha=0.5) +
  facet_wrap(~start_time)
@
\end{frame}


\begin{frame}
\frametitle{Delay in data analysis}

Suppose you have a one or two week delay in collecting, processing, and analyzing so that when trying to forecast future states you are using ``old'' data, \pause i.e.

Real-time:
\[ 
p(X_{t+1:T}|\theta,\lambda,X_{t})
\]

One-week delay:
\[ 
p(X_{t+1:T}|\theta,\lambda,X_{t-1})
\]

Two-week delay:
\[ 
p(X_{t+1:T}|\theta,\lambda,X_{t-2})
\]
\end{frame}



\begin{frame}
\frametitle{}
<<delayed_data>>=
# Initial simulation
sir = sckm('sir')
n = 52
d = tau_leap(sir, n)
d$X = as.data.frame(d$X)
names(d$X) = sir$states
d$X$time = 0:n
d$X = d$X 

# For each time-point forward simulate to the end
# and then calculate quantiles
dd = ddply(d$X, .(time), function(x) {
  rdply(1e3, {
    sir = sckm('sir')
    sir$X = x[,c("S","I","R")]
    d = tau_leap(sir, 3)
    d$X = as.data.frame(d$X)
    names(d$X) = sir$states
#    d$X$time = x$start_time + 0:3
    d$X$delay = c(NA,'none','one week','two weeks')
    d$X  %>% 
      na.omit %>%
      gather(state, count, -delay)
  })
})

q = dd %>%
  group_by(time,delay,state) %>%
  summarise(L = quantile(count,.025),
            U = quantile(count,.975)) 
@

<<dependson='perfect_forecasts'>>=
ggplot(q, aes(time, ymin=L, ymax=U, fill=state)) +
  geom_ribbon(alpha=0.5) + 
  facet_wrap(~delay)
@
\end{frame}

\begin{frame}
<<dependson='perfect_forecasts'>>=
ggplot(q %>% filter(state=='I'), aes(time, ymin=L, ymax=U, fill=state)) +
  geom_ribbon(alpha=0.5) + 
  facet_wrap(~delay)
@
\end{frame}



\section{Forecasting with noisily observed state}
\begin{frame}
\frametitle{Forecasting with noisily observed state}

In reality, we know the transition rates ($\lambda$) and the observation probabilities ($\theta$), but we only observe a noisy version of the state transitions, i.e. . 
\[
Y_{tk} \stackrel{ind}{\sim} Bin(\Delta X_{tk},\theta_{k}).
\]

Now the forecast distribution we need is 
\[
p(X_{t+1:T}|\lambda,\theta, y_{0:t}) = \int p(X_{t+1:T}\lambda,\theta|X_{t})p(X_{t}|\lambda,\theta, y_{0:t}) dX_{t}.
\]

\end{frame}



% \begin{frame}
% \frametitle{Noisy observation}
% 
% Recall, we model state transitions using Poisson distributions, i.e. \[ 
% \begin{array}{rll}
% 	\Delta X_{tk} &\stackrel{ind}{\sim} Po(\lambda_{k} f_k(X_{t-1})), \\
% 	X_{tm} &= X_{t-1,m} + \sum_{k=1}^K v_{mk} \Delta X_{tk}, & m=1,\ldots,M 
% \end{array}
% \]
% where $f_k(\cdot)$ are known functions and $v_{mk}$ is a known \emph{stoichiometry}. 
% 
% \vspace{0.2in} 
% 
% We assume the transitions $\Delta X_{tk}$ are partially observed through a binomial distribution, i.e. 
% \[ 
% Y_{tk} \stackrel{ind}{\sim} Bin(\Delta X_{tk},\theta_{k}).
% \]
% \end{frame}




\begin{frame}
<<noisy_observations>>=
sir = sckm('sir')
n = 52
d = tau_leap(sir, n)
d$nr = as.data.frame(d$nr)
names(d$nr) = c('SI','IR')
d$nr$time = 1:n 

dd = ddply(expand.grid(p_SI = seq(0,1,by=1/5),
                      p_IR = seq(0,1,by=1/5)),
          .(p_SI,p_IR), 
          function(x,df) {
  data.frame(SI = rbinom(nrow(df), df$SI, x$p_SI),
             IR = rbinom(nrow(df), df$IR, x$p_IR),
             time=df$time) 
}, df=d$nr)
@

<<noisy_observations_data, dependson='noisy_observations'>>=
dd$p_SI_formatted = paste('S to I:', dd$p_SI)
dd$p_IR_formatted = paste('I to R:', dd$p_IR)
ggplot(dd %>%
         select(SI, IR, time, p_SI_formatted, p_IR_formatted) %>% 
         gather(transition, count, -time, -p_SI_formatted, -p_IR_formatted), 
       aes(time,count,color=transition,shape=transition)) + 
  geom_point() +
  facet_grid(p_IR_formatted~p_SI_formatted)
@
\end{frame}


% ' \begin{frame}
% ' \frametitle{Noisily observed state}
% ' <<dependson='noisy_observations'>>=
% ' sir = sckm('sir')
% '
% ' # Prior
% ' prior_ =
% '
% ' tlpl = ddply(dd %>% filter(time<15), .(p_SI,p_IR), function(x) {
% '   nn = 10000 # to make prior informative
% '   pp = c(x$p_SI[1], x$p_IR[1])
% '   prior_  = list(rate = list(a = nn*sir$theta, b = nn),
% '                  prob = list(a = nn*pp, b = nn*(1-pp)),
% '                  X = sir$X)
% '
% '   tlpl = tlpl(list(y=x %>% select('SI','IR'), tau=1),
% '             sckm = sir,
% '             prior = prior_,
% '             n.particles = 10000)
% '   tlpl_predict(sir,52-15,tlpl)$X
% ' })
% ' @
% ' \end{frame}





\end{document}
